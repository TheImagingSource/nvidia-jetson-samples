{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using MIPI Sensors with GStreamer\n",
    "\n",
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we want to display a live video image. This could be done easily with an `Image`-widget. Let's create one here so we could use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "image_widget = ipywidgets.Image(format=\"jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the GStreamer module, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gi\n",
    "gi.require_version(\"Gst\", \"1.0\")\n",
    "from gi.repository import Gst\n",
    "\n",
    "Gst.init(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline that scales the video stream to 640x480 using the accelerated scaler/converter *nvvidconv*. Then encode the result as a jpeg using the accelerated video encoder *nvjpegenc*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Gst.parse_launch(\"nvarguscamerasrc name=src ! \" \\\n",
    "                            \"nvvidconv ! \" \\\n",
    "                            \"video/x-raw(memory:NVMM),width=640,height=480 ! \" \\\n",
    "                            \"nvjpegenc ! \"\\\n",
    "                            \"appsink max-buffers=1 name=sink\")\n",
    "# Start the pipeline, then wait for it to run\n",
    "pipeline.set_state(Gst.State.PLAYING)\n",
    "pipeline.get_state(Gst.CLOCK_TIME_NONE)\n",
    "\n",
    "# Get our src and sink elements to work with\n",
    "src = pipeline.get_by_name(\"src\")\n",
    "sink = pipeline.get_by_name(\"sink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether we get a valid jpeg image, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sink.emit(\"try-pull-sample\", 1 * Gst.SECOND)\n",
    "print(\"Caps:\", sample.get_caps().to_string())\n",
    "buffer = sample.get_buffer()\n",
    "print(\"Got a buffer of size: %d Bytes\" % (buffer.get_size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we get jpeg images at the appsink, we could feed them to the image widget we created earlier for display. \n",
    "\n",
    "To do this, we connect to the `new-sample` signal of the appsink. We also need to enable the elements signals via the `emit-signals` property. Finally, we have to pull a sample from the appsink since the appsinks buffer queue is already full right now and new samples can only arrive if there is room in the buffer queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal handler called when a new sample arrives at the appsink\n",
    "def on_new_sample(sink, image_widget):\n",
    "    sample = sink.emit(\"pull-sample\")\n",
    "    buffer = sample.get_buffer()\n",
    "    result, mapinfo = buffer.map(Gst.MapFlags.READ)\n",
    "    if result:\n",
    "        image_widget.value = mapinfo.data\n",
    "        buffer.unmap(mapinfo)\n",
    "    return Gst.FlowReturn.OK\n",
    "\n",
    "sink.connect(\"new-sample\", on_new_sample, image_widget)\n",
    "# Signals are not emmited unless enabled\n",
    "sink.set_property(\"emit-signals\", True)\n",
    "# Flush the buffer currently in the appsink, so that new buffers can arrive\n",
    "sink.emit(\"pull-sample\")\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's add some controls to change camera properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_slider = ipywidgets.FloatSlider(min=-2, max=2, description=\"ExposureCompensation\")\n",
    "exp_slider.observe(lambda change: src.set_property(\"exposurecompensation\", change.new), \"value\")\n",
    "display(exp_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_slider = ipywidgets.FloatSlider(min=0, max=2, default=1, description=\"Saturation\")\n",
    "sat_slider.observe(lambda change: src.set_property(\"saturation\", change.new), \"value\")\n",
    "display(sat_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to shut down the pipeline when we are done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_state(Gst.State.NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
