*IMPORTANT* Change first time settings at the /Desktop/Welcome.htmp page: change a time zone, select a model of your camera(s) and restart to apply changes before running following examples.

There is folowing examples available:
1.  Live view
2.  h.264/h.265 streaming
3.  How to pull Nvidia Deepstream docker container
4.  Face detection with Nvidia Deepstream Gstreamer pipeline
5.  Mask detection with Nvidia Deepstream app
6.  Hpeek image processing
7.  Hpeek deep learning 

***
1.  Live view

    This example displays a video from the camera with a Gstreamer pipeline. 
    Run this script by double clicking on it or by executing this command in terminal:

    $ ./liveview_cam0.sh
    OR
    $ ./liveview_cam1.sh

***
2.  h.264/h.265 streaming

    This example demonstrates how an h.264 (h.265) encoded stream can be created and how to receive and decode it on another computer.
    Run the streamimg part of the example by double clicking on the script file or by executing this command in terminal:

    $ ./h264streaming.sh
    OR
    $ ./h265streaming.sh

    Copy the receiveH264stream.sdp (receiveH265stream.sdp) file to a computer that will receive the stream and view the video in a suitable player (e.g. VLC). Make sure that all the receiving computers are in the same local network as the streaming Jetson.

***
3.  How to pull Nvidia Deepstream docker container

    This example shows how to pull the Nvidia docker container for Deepstream and how to run a Gstreamer pipeline with Deepstream plugins for the face detection with a camera.
    Pull the Deepstream container with samples for Linux for Tegra (see http://ngc.nvidia.com/catalog/containers/nvidia:deepstream-l4t for an updated source link):

    $ sudo docker pull nvcr.io/nvidia/deepstream-l4t:5.0.1-20.09-samples

    Allow external applications to connect to the host's X display:

    $ xhost +

    Create an instance of the deepstream container adding desired name to the container (with --name <name> tag):

    $ sudo docker create -it --name deepstream_samples --net=host --runtime nvidia -e DISPLAY=$DISPLAY -w /opt/nvidia/deepstream/deepstream-5.0 -v /tmp/argus_socket:/tmp/argus_socket --device /dev/video0 -v /home/jupyter/Desktop/Examples/DeepLearning/:/tmp/DeepLearning -v /tmp/.X11-unix/:/tmp/.X11-unix nvcr.io/nvidia/deepstream-l4t:5.0.1-20.09-samples
    
    Start the deepstream_samples container
        
    $ sudo docker start -ia deepstream_samples

***
4.  Face detection with Nvidia Deepstream Gstreamer pipeline

    Follow all steps from the example 3 before proceeding to this one.

    Start the deepstream_samples container:

    $ sudo docker start -ia deepstream_samples

    Create a directory for face detection models and download the files:

    $ cd samples/configs/tlt_pretrained_models/

    $ mkdir -p ../../models/tlt_pretrained_models/facedetectir

    $ wget https://api.ngc.nvidia.com/v2/models/nvidia/tlt_facedetectir/versions/pruned_v1.0/files/resnet18_facedetectir_pruned.etlt -O ../../models/tlt_pretrained_models/facedetectir/resnet18_facedetectir_pruned.etlt

    $ wget https://api.ngc.nvidia.com/v2/models/nvidia/tlt_facedetectir/versions/pruned_v1.0/files/facedetectir_int8.txt -O ../../models/tlt_pretrained_models/facedetectir/facedetectir_int8.txt

    Start an inference for face detection with one camera:

    $ gst-launch-1.0 nvarguscamerasrc bufapi-version=1 ! nvvideoconvert ! m.sink_0 nvstreammux name=m batch-size=1 width=1948 height=1096 live-source=1 ! nvinfer config-file-path=/opt/nvidia/deepstream/deepstream-5.0/samples/configs/tlt_pretrained_models/config_infer_primary_facedetectir.txt batch-size=1 unique-id=1 ! nvtracker ll-lib-file=/opt/nvidia/deepstream/deepstream-5.0/lib/libnvds_mot_klt.so ! nvmultistreamtiler rows=1 columns=1 width=1280 height=720 ! nvdsosd ! nvegltransform ! nveglglessink

***
5.  Mask detection with Nvidia Deepstream app

    Follow all steps from the example 3 before proceeding to this one.

    Start the deepstream_samples container and enter the MaskDetect/ directory:

    $ sudo docker start -ia deepstream_samples
    $ cd /tmp/DeepLearning/MaskDetect

    Download a pre-trained model. If you are running this example on Jetson Nano, get the pruned (optimized) model (resnet18_mask_detector.etlt). if youare on Jetson Xavier NX, you can get the unpruned model (resnet18_mask_detector_unpruned.etlt) for better detection. Pruned:

    $ wget https://github.com/TheImagingSource/nvidia-jetson-samples/raw/master/examples/deep-learning/maskdetect/resnet18_mask_detector.etlt -O resnet18_mask_detector.etlt

    Unpruned:

    $ wget https://github.com/TheImagingSource/nvidia-jetson-samples/raw/master/examples/deep-learning/maskdetect/resnet18_mask_detector_unpruned.etlt -O resnet18_mask_detector_unpruned.etlt

    Start the Deepstream:
    
    $ deepstream-app -c deepstream_app_source1_maskdetect.txt

    You can change configuration in deepstream_app_source1_maskdetect.txt and config_maskdetect.txt to adapt this example for your setup.
    
***
6.  Hpeek image processing

    This example is created by MVTec as a presentation to show image processing capabilities of HALCON - software for industrial machine vision.
    Run this example by double clicking on the script file or execute it in terminal:

    $ ./sneak_a_peek_with_hpeek.sh

***
7.  Hpeek deep learning

    This example is created by MVTec as a presentation to show deep learning capabilities of HALCON - software for industrial machine vision.
    Run this example by double clicking on the script file or execute it in terminal:

    $ ./deep_learning_with_hpeek.sh
